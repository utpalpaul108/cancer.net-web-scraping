{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancer Types Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/utpal108/dev/Python/Projects/cancer.net-web-scraping'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webScraping.constants import *\n",
    "from webScraping.utils import getSectionUrl, getFullUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components\n",
    "class DataExtraction:\n",
    "\n",
    "    def __init__(self, dir_name):\n",
    "        self.headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "        self.dir_path = os.path.join('artifacts','data',dir_name)\n",
    "        self.skip_contents = skip_contents\n",
    "        self.partially_skip_contents = partially_skip_contents\n",
    "        os.makedirs(self.dir_path, exist_ok=True)      \n",
    "    \n",
    "    def get_cancer_catalogs(self, URL):\n",
    "        response = requests.get(URL, headers = self.headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        cancer_catalogs = soup.find('div', id='quicktabs-container-cancer_types')\n",
    "        cancer_catalogs = cancer_catalogs.select('div .quicktabs-tabpage')\n",
    "        return cancer_catalogs\n",
    "    \n",
    "    def get_cancer_details_url(self, cancer_url):\n",
    "        cancer_details_url = requests.get(cancer_url, headers = self.headers)\n",
    "        soup = BeautifulSoup(cancer_details_url.content, 'html.parser')\n",
    "        view_all_link = soup.find('a', string='View All Pages')\n",
    "        \n",
    "        if view_all_link:\n",
    "            cancer_details_url = getFullUrl(view_all_link['href']) \n",
    "        else:\n",
    "            cancer_details_url = cancer_url\n",
    "        \n",
    "        return cancer_details_url\n",
    "    \n",
    "    def get_cancer_details(self, cancer_url, cancer_name):\n",
    "        \n",
    "        cancer_details = requests.get(cancer_url, headers = self.headers)\n",
    "        soup = BeautifulSoup(cancer_details.content, 'html.parser')\n",
    "        \n",
    "        df = {\n",
    "            'question':[],\n",
    "            'answer':[]\n",
    "        }\n",
    "\n",
    "        questions = soup.find_all('h3')\n",
    "        skip_contents = [content.lower() for content in self.skip_contents]\n",
    "        partially_skip_contents = [content.lower() for content in self.partially_skip_contents]\n",
    "        questions = [question for question in questions if question.text.strip() != '' and question.text.strip().lower() not in skip_contents and not any(re.findall(r\"\\b(\" + \"|\".join(partially_skip_contents) + r\")\\b\", question.text.strip().lower()))]\n",
    "        \n",
    "        for question in questions:\n",
    "            df['question'].append(question.text.strip())\n",
    "            answer = \"\"\n",
    "            next_element = question.find_next_sibling()\n",
    "            while next_element and next_element.name != 'h3':\n",
    "                answer += next_element.text.strip() + \" \"\n",
    "                next_element = next_element.find_next_sibling()\n",
    "            \n",
    "            df['answer'].append(answer)\n",
    "\n",
    "        if len(df['question']) > 0 and len(df['answer']) > 0:\n",
    "            data_path = os.path.join(self.dir_path,cancer_name+'.csv')\n",
    "            df = pd.DataFrame(df)\n",
    "            df.to_csv(data_path, index=False)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extraction = DataExtraction('cancer-types')\n",
    "cancer_catalogs = data_extraction.get_cancer_catalogs('https://www.cancer.net/cancer-types')\n",
    "for cancer_catalog in cancer_catalogs:\n",
    "    cancer_types = cancer_catalog.select('.view .view-content .item-list ul li')\n",
    "    for cancer_type in cancer_types:\n",
    "        base_url = getFullUrl(cancer_type.find('a').get('href'))\n",
    "        cancer_name = base_url.split('/')[-1]       \n",
    "        cancer_details_url = data_extraction.get_cancer_details_url(base_url)\n",
    "        cancer_details = data_extraction.get_cancer_details(cancer_details_url, cancer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "try:\n",
    "    data_extraction = DataExtraction('cancer-types')\n",
    "    cancer_catalogs = data_extraction.get_cancer_catalogs('https://www.cancer.net/cancer-types')\n",
    "    for cancer_catalog in cancer_catalogs:\n",
    "        try:\n",
    "            cancer_types = cancer_catalog.select('.view .view-content .item-list ul li')\n",
    "            for cancer_type in cancer_types:\n",
    "                try:\n",
    "                    base_url = getFullUrl(cancer_type.find('a').get('href'))\n",
    "                    cancer_name = base_url.split('/')[-1]       \n",
    "                    cancer_details_url = data_extraction.get_cancer_details_url(base_url)\n",
    "                    cancer_details = data_extraction.get_cancer_details(cancer_details_url, cancer_name)\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
