{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research and Advocacy Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/utpal108/dev/Python/Projects/cancer.net-web-scraping'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webScraping.constants import *\n",
    "from webScraping.utils import getSectionUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components\n",
    "class DataExtraction:\n",
    "\n",
    "    def __init__(self, dir_name):\n",
    "        self.headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "        self.dir_path = os.path.join('artifacts','data',dir_name)\n",
    "        self.skip_contents = skip_contents\n",
    "        self.partially_skip_contents = partially_skip_contents\n",
    "        os.makedirs(self.dir_path, exist_ok=True)\n",
    "        \n",
    "\n",
    "    def get_sections(self, URL):\n",
    "    \n",
    "        response = requests.get(URL, headers = self.headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        sections_url = []\n",
    "        sections = soup.find('article')\n",
    "        sections = sections.find('div', class_='field-name-field-page-sub-pages').find('div', class_='field-items')\n",
    "        sections = sections.find_all('article')\n",
    "        \n",
    "\n",
    "        for section in sections:\n",
    "            sections_url.append(getSectionUrl(section))\n",
    "\n",
    "        return sections_url\n",
    "    \n",
    "\n",
    "    def get_section_topics(self, section_url):\n",
    "        response = requests.get(section_url, headers = self.headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        section_topics_url = []\n",
    "        section_topics = soup.find('article')\n",
    "        \n",
    "        section_topics = section_topics.find('div',class_='field-name-field-page-sub-pages')\n",
    "        if section_topics is None:\n",
    "            self.get_topic_content(section_url)\n",
    "        \n",
    "        else:\n",
    "            section_topics = section_topics.find('div',class_='field-items')\n",
    "\n",
    "            for section_topic in section_topics:\n",
    "                section_topics_url.append(getSectionUrl(section_topic))\n",
    "        \n",
    "        return section_topics_url\n",
    "    \n",
    "\n",
    "    def get_topic_content(self, topic_url):\n",
    "\n",
    "        response = requests.get(topic_url, headers = self.headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        df  = {\n",
    "            'question':[],\n",
    "            'answer':[]\n",
    "        }\n",
    "\n",
    "        articles = soup.find_all('article')\n",
    "        \n",
    "        if len(articles) > 1:\n",
    "            section_topics = self.get_section_topics(topic_url)\n",
    "            for section_topic_url in section_topics:\n",
    "                self.get_topic_content(section_topic_url)\n",
    "        \n",
    "        topic_name = topic_url.split('/')[-1]\n",
    "        questions = soup.find_all('h3')\n",
    "        skip_contents = [content.lower() for content in self.skip_contents]\n",
    "        partially_skip_contents = [content.lower() for content in self.partially_skip_contents]\n",
    "        questions = [question for question in questions if question.text.strip() != '' and question.text.strip().lower() not in skip_contents and not any(re.findall(r\"\\b(\" + \"|\".join(partially_skip_contents) + r\")\\b\", question.text.strip().lower()))]\n",
    "        \n",
    "        for question in questions:\n",
    "            df['question'].append(question.text.strip())\n",
    "            \n",
    "            answer = \"\"\n",
    "            next_element = question.find_next_sibling()\n",
    "            while next_element and next_element.name != 'h3':\n",
    "                answer += next_element.text.strip() + \" \"\n",
    "                next_element = next_element.find_next_sibling()\n",
    "            \n",
    "            df['answer'].append(answer)\n",
    "\n",
    "        \n",
    "        if len(df['question']) > 0 and len(df['answer']) > 0:\n",
    "            data_path = os.path.join(self.dir_path,topic_name+'.csv')\n",
    "            df = pd.DataFrame(df)\n",
    "            df.to_csv(data_path, index=False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.cancer.net/research-and-advocacy/introduction-cancer-research/understanding-publication-and-format-cancer-research-studies\n",
      "https://www.cancer.net/research-and-advocacy/introduction-cancer-research/understanding-cancer-research-study-design-and-how-evaluate-results\n",
      "https://www.cancer.net/research-and-advocacy/introduction-cancer-research/how-are-cancer-drugs-discovered-and-developed\n",
      "https://www.cancer.net/research-and-advocacy/introduction-cancer-research/drug-approval-and-labeling-united-states\n",
      "https://www.cancer.net/research-and-advocacy/introduction-cancer-research/evaluating-cancer-information-internet\n",
      "https://www.cancer.net/research-and-advocacy/introduction-cancer-research/how-patient-advocates-help-cancer-research-expert-qa\n",
      "https://www.cancer.net/research-and-advocacy/introduction-cancer-research/journals-and-magazines\n",
      "https://www.cancer.net/research-and-advocacy/clinical-trials/about-cancer-clinical-trials\n",
      "https://www.cancer.net/research-and-advocacy/clinical-trials/patient-safety-clinical-trials\n",
      "https://www.cancer.net/research-and-advocacy/clinical-trials/phases-clinical-trials\n",
      "https://www.cancer.net/research-and-advocacy/clinical-trials/health-insurance-coverage-clinical-trials\n",
      "https://www.cancer.net/research-and-advocacy/clinical-trials/placebos-cancer-clinical-trials\n",
      "https://www.cancer.net/research-and-advocacy/clinical-trials/questions-ask-about-clinical-trials\n",
      "https://www.cancer.net/research-and-advocacy/clinical-trials/finding-clinical-trial\n",
      "https://www.cancer.net/research-and-advocacy/clinical-trials/what-tapur-study\n",
      "https://www.cancer.net/research-and-advocacy/clinical-trials/welcome-pre-act\n",
      "https://www.cancer.net/research-and-advocacy/asco-annual-meetings/news-highlights-day\n",
      "https://www.cancer.net/research-and-advocacy/asco-annual-meetings/how-follow-ascos-annual-meeting-our-social-media\n",
      "https://www.cancer.net/research-and-advocacy/asco-annual-meetings/archive-past-asco-annual-meetings\n",
      "https://www.cancer.net/research-and-advocacy/patient-advocates/patient-advocate-programs-asco-annual-meeting\n",
      "https://www.cancer.net/blog/2020-06/cancer-does-not-affect-all-people-equally-expert-qa-cancer-disparities-and-health-equity\n",
      "https://www.cancer.net/research-and-advocacy/health-disparities-and-cancer/resources-cancer-disparities-and-health-equity\n",
      "https://www.cancer.net/blog/tags/health-equity\n",
      "https://www.cancer.net/research-and-advocacy/patient-advocates/being-cancer-advocate\n",
      "https://www.cancer.net/research-and-advocacy/patient-advocates/patient-advocate-programs-asco-annual-meeting\n",
      "https://www.cancer.net/research-and-advocacy/patient-advocates/patient-advocate-programs-asco-symposia\n",
      "https://www.cancer.net/research-and-advocacy/patient-advocates/conquer-cancer-patient-advocate-scholarship-program\n",
      "https://www.cancer.net/research-and-advocacy/patient-advocates/tips-getting-started-social-media\n"
     ]
    }
   ],
   "source": [
    "data_extraction = DataExtraction('research-and-advocacy')\n",
    "sections = data_extraction.get_sections('https://www.cancer.net/research-and-advocacy')\n",
    "for section_url in sections:\n",
    "    section_topics = data_extraction.get_section_topics(section_url)\n",
    "    for section_topic_url in section_topics:\n",
    "        print(section_topic_url)\n",
    "        data_extraction.get_topic_content(section_topic_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "try:\n",
    "    data_extraction = DataExtraction('research-and-advocacy')\n",
    "    sections = data_extraction.get_sections('https://www.cancer.net/research-and-advocacy')\n",
    "    for section_url in sections:\n",
    "        try:\n",
    "            section_topics = data_extraction.get_section_topics(section_url)\n",
    "            for section_topic_url in section_topics:\n",
    "                try:\n",
    "                    data_extraction.get_topic_content(section_topic_url)\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
